{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c5dfa1-2b7d-452b-a4cf-c88cf60ad1d2",
   "metadata": {},
   "source": [
    "# Ray Architecture and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6efdfe-1158-4d89-8469-03cee2d0780c",
   "metadata": {},
   "source": [
    "[Ray Cluster](https://docs.ray.io/en/latest/cluster/key-concepts.html#id3)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#ray-cluster \"Permalink to this headline\")\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "A Ray cluster consists of a single [head node](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-head-node) and any number of connected [worker nodes](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-worker-nodes):\n",
    "\n",
    "[![../_images/ray-cluster.svg](https://docs.ray.io/en/latest/_images/ray-cluster.svg)](https://docs.ray.io/en/latest/_images/ray-cluster.svg)\n",
    "\n",
    "*A Ray cluster with two worker nodes. Each node runs Ray helper processes to facilitate distributed scheduling and memory management. The head node runs additional control processes (highlighted in blue).*[](https://docs.ray.io/en/latest/cluster/key-concepts.html#id1 \"Permalink to this image\")\n",
    "\n",
    "The number of worker nodes may be *autoscaled* with application demand as specified by your Ray cluster configuration. The head node runs the [autoscaler](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-autoscaler).\n",
    "\n",
    "> Note: Ray nodes are implemented as pods when [running on Kubernetes](https://docs.ray.io/en/latest/cluster/kubernetes/index.html#kuberay-index).\n",
    "\n",
    "Users can submit jobs for execution on the Ray cluster, or can interactively use the cluster by connecting to the head node and running [`ray.init`](https://docs.ray.io/en/latest/ray-core/package-ref.html#ray.init \"ray.init\"). See [Ray Jobs](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/quickstart.html#jobs-quickstart) for more information.\n",
    "\n",
    "[Head Node](https://docs.ray.io/en/latest/cluster/key-concepts.html#id4)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#head-node \"Permalink to this headline\")\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Every Ray cluster has one node which is designated as the *head node* of the cluster. The head node is identical to other worker nodes, except that it also runs singleton processes responsible for cluster management such as the [autoscaler](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-autoscaler) and the Ray driver processes [which run Ray jobs](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-clients-and-jobs). Ray may schedule tasks and actors on the head node just like any other worker node, unless configured otherwise.\n",
    "\n",
    "[Worker Node](https://docs.ray.io/en/latest/cluster/key-concepts.html#id5)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#worker-node \"Permalink to this headline\")\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "*Worker nodes* do not run any head node management processes, and serve only to run user code in Ray tasks and actors. They participate in distributed scheduling, as well as the storage and distribution of Ray objects in [cluster memory](https://docs.ray.io/en/latest/ray-core/scheduling/memory-management.html#memory).\n",
    "\n",
    "[Autoscaling](https://docs.ray.io/en/latest/cluster/key-concepts.html#id6)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#autoscaling \"Permalink to this headline\")\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "The *Ray autoscaler* is a process that runs on the [head node](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-head-node) (or as a sidecar container in the head pod if [using Kubernetes](https://docs.ray.io/en/latest/cluster/kubernetes/index.html#kuberay-index)). When the resource demands of the Ray workload exceed the current capacity of the cluster, the autoscaler will try to increase the number of worker nodes. When worker nodes sit idle, the autoscaler will remove worker nodes from the cluster.\n",
    "\n",
    "It is important to understand that the autoscaler only reacts to task and actor resource requests, and not application metrics or physical resource utilization. To learn more about autoscaling, refer to the user guides for Ray clusters on [VMs](https://docs.ray.io/en/latest/cluster/vms/index.html#cloud-vm-index) and [Kubernetes](https://docs.ray.io/en/latest/cluster/kubernetes/index.html#kuberay-index).\n",
    "\n",
    "[Ray Jobs](https://docs.ray.io/en/latest/cluster/key-concepts.html#id7)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#ray-jobs \"Permalink to this headline\")\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "A Ray job is a single application: it is the collection of Ray tasks, objects, and actors that originate from the same script. The worker that runs the Python script is known as the *driver* of the job.\n",
    "\n",
    "There are three ways to run a Ray job on a Ray cluster:\n",
    "\n",
    "1.  (Recommended) Submit the job using the [Ray Jobs API](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html#jobs-overview).\n",
    "\n",
    "2.  Run the driver script directly on any node of the Ray cluster, for interactive development.\n",
    "\n",
    "3.  Use [Ray Client](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/ray-client.html#ray-client-ref) to connect remotely to the cluster within a driver script.\n",
    "\n",
    "For details on these workflows, refer to the [Ray Jobs API guide](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html#jobs-overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f08d0-725a-4eec-8be0-0bb3686f950b",
   "metadata": {},
   "source": [
    "`pip install -U \"ray[air]\" # installs Ray + dependencies for Ray AI Runtime`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
